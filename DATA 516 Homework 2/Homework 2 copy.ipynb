{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2\n",
    "\n",
    "### Grader note! Markdown Answers in the Last Cell\n",
    "---\n",
    "---\n",
    "## ML Modeling within Redshift\n",
    "\n",
    "**Amazon Redshift ML**\n",
    "\n",
    "Redshift has the ability to perform machine learning within a cluster. This eliminates the need to build custom pipelines to move data in and out of the cluster for processing in a data model. Redshift supports a variety of models, and you can even bring your own. You can learn more about Redshift's ML features on [its product page](https://aws.amazon.com/redshift/features/redshift-ml/).\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "Before starting, consider the following prerequisites:\n",
    "\n",
    "- Plan your time: the model training portion of the assignment may take up to one hour.\n",
    "- Resources: This walkthrough will consume about $12.00 of your lab budget.\n",
    "- Ensure you are always working in the `us-east-1` region.\n",
    "- On the Amazon S3 console, create an S3 bucket that Redshift ML uses for uploading the training data that Forecast uses to train the model.\n",
    "  - Bucket names need to be globally unique, so use your UW Net ID to help enforce uniqueness. For example, my bucket name is: `uw-kazzazmk-mlredshift`.\n",
    "- You should be running a Redshift cluster similar to what you did during the hands-on portion in class. If you need a refresher, [check out our notes from class](https://gitlab.cs.washington.edu/mmkazzaz/csed516-2024au/-/blob/main/admin/redshift/redshift_cluster_parameters.md?ref_type=heads).\n",
    "- Use the `LabRole` IAM role whenever an IAM role is required.\n",
    "- Remember to only run your Redshift cluster when you are using it. \n",
    "  - Pause or terminate it when it's not in use. \n",
    "  - If not, you risk running out of lab credits for our class, and you will need to pay for your own AWS usage.\n",
    "\n",
    "**Submission Requirements**\n",
    "- Use a Redshift Notebook via the Query Editor V2 to paste, update, and run all of the below commands.\n",
    "- Use a final markdown cell to answer the questions at the end of these instructions.\n",
    "- Upload your executed Redshift Notebook to complete the assignment.\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting customer churn via classification model**\n",
    "\n",
    "For this assignment, we will perform classification prediction. We will use data to label whether or not customers have churned. Customer churn refers to the loss of customers over a period of time. It happens when customers stop using a company's product or service, and it is often used as a key measure to understand customer loyalty and retention.\n",
    "\n",
    "We will use a version of the Iranian Churn data set from the UCI Machine Learning Repository. The original source is available via [UC Irvine's Machine Learning Repository](https://archive.ics.uci.edu/dataset/563/iranian+churn+dataset). For our purpose, we will use a modified copy of the data hosted by AWS:\n",
    "- Via S3: `s3://redshift-downloads/redshift-ml/customer_activity/`\n",
    "\n",
    "Let's get this table loaded into Redshift. Complete the below DDL statements to create and load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE SCHEMA DEMO_ML\n",
    ";\n",
    "\n",
    "CREATE TABLE demo_ml.customer_activity (\n",
    "state varchar(2), \n",
    "account_length int, \n",
    "area_code int,\n",
    "phone varchar(8), \n",
    "intl_plan varchar(3), \n",
    "vMail_plan varchar(3),\n",
    "vMail_message int, \n",
    "day_mins float, \n",
    "day_calls int, \n",
    "day_charge float,\n",
    "total_charge float,\n",
    "eve_mins float, \n",
    "eve_calls int, \n",
    "eve_charge float, \n",
    "night_mins float,\n",
    "night_calls int, \n",
    "night_charge float, \n",
    "intl_mins float, \n",
    "intl_calls int,\n",
    "intl_charge float, \n",
    "cust_serv_calls int, \n",
    "churn varchar(6),\n",
    "record_date date)\n",
    ";\n",
    "\n",
    "COPY DEMO_ML.customer_activity \n",
    "FROM 's3://redshift-downloads/redshift-ml/customer_activity/' \n",
    "IAM_ROLE '${IAM_ROLE}'\n",
    "delimiter ',' \n",
    "IGNOREHEADER 1  \n",
    "region 'us-east-1'\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Forecast Model**\n",
    "\n",
    "For Redshift ML forecasting model, you need to ensure that when you issue a CREATE MODEL statement, you specify `MODEL_TYPE` as `FORECAST`. When Redshift ML trains a model or predictor on Amazon Forecast, it has a fixed forecast, meaning there is not a physical model to compile and execute.\n",
    "\n",
    "**Heads up! The next command may take up to one hour to complete.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE MODEL demo_ml.customer_churn_model\n",
    "FROM (SELECT state,\n",
    "             area_code,\n",
    "             total_charge/account_length AS average_daily_spend, \n",
    "             cust_serv_calls/account_length AS average_daily_cases,\n",
    "             churn \n",
    "      FROM demo_ml.customer_activity\n",
    "         WHERE record_date < '2020-01-01' \n",
    "\n",
    "     )\n",
    "TARGET churn\n",
    "FUNCTION predict_customer_churn\n",
    "IAM_ROLE '${IAM_ROLE}'\n",
    "SETTINGS (\n",
    "  S3_BUCKET '${BUCKET_NAME}'\n",
    ")\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SELECT query in the FROM clause specifies the training data. The TARGET clause specifies which column is the label that the CREATE MODEL builds a model to predict. The other columns in the training query are the features (input) used for the prediction. In this example, the training data provides features regarding state, area code, average daily spend, and average daily cases for the customers that have been active earlier than January 1, 2020. The target column churn indicates whether the customer still has an active membership or has suspended their membership. For more information about CREATE MODEL syntax, see the [Amazon Redshift Database Developer Guide](https://docs.aws.amazon.com/redshift/latest/dg/machine_learning-overview.html).\n",
    "\n",
    "Creating a model in Redshift takes some time. Before we can move on, we will need to wait until our model is ready. Run the following query every few minutes until you see Model State transition from **TRAINING** to **READY**.\n",
    "\n",
    "Redshift is working with SageMaker to run training, transform, and hypertuning jobs. You can track the progress by navigating to the SageMaker Dashboard: https://us-east-1.console.aws.amazon.com/sagemaker/home?region=us-east-1#/dashboard. The long pole of the process is SageMaker hypertuning the parameters. Once the Hypertuning starts, it will execute 100 training jobs. Once those jobs complete, our model will be ready for use.\n",
    "\n",
    "For reference, when creating this assignment, it took just under an hour for my model to be ready.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW MODEL demo_ml.customer_churn_model\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reviewing our model**\n",
    "\n",
    "Wth our model ready, we can now evaluate how well it performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH infer_data AS (\n",
    "  SELECT area_code ||phone  accountid, churn,\n",
    "    demo_ml.predict_customer_churn( \n",
    "          state,\n",
    "          area_code, \n",
    "          total_charge/account_length , \n",
    "          cust_serv_calls/account_length ) AS predicted\n",
    "  FROM demo_ml.customer_activity\n",
    "WHERE record_date <  '2020-01-01'\n",
    "\n",
    ")\n",
    "SELECT * FROM infer_data\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look further at the instances where our model was wrong. This function will present the label probabilities alongside the predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH infer_data AS (\n",
    "  SELECT area_code ||phone  accountid, churn,\n",
    "    demo_ml.predict_customer_churn_prob( \n",
    "          state,\n",
    "          area_code, \n",
    "          total_charge/account_length , \n",
    "          cust_serv_calls/account_length ) AS predicted\n",
    "  FROM demo_ml.customer_activity\n",
    "WHERE record_date <  '2020-01-01'\n",
    "\n",
    ")\n",
    "SELECT *  FROM infer_data where churn!=predicted\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use our ML model for inference**\n",
    "\n",
    "The value of an model comes from using it to inference results on non-training data. In our case, we trained our data on activity prior to 2020. Let's run our model against records starting in 2020 for area code 408.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT area_code ||phone  accountid, \n",
    "       demo_ml.predict_customer_churn( \n",
    "          state,\n",
    "          area_code, \n",
    "          total_charge/account_length , \n",
    "          cust_serv_calls/account_length )\n",
    "          AS \"predictedActive\"\n",
    "FROM demo_ml.customer_activity\n",
    "WHERE area_code='408' and record_date > '2020-01-01'\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "Remember to pause/terminate your instance. Upload your executed notebook to Canvas to gain credit for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Notes From the Process\n",
    "\n",
    "- Make sure to select the AWS secrets manager in 'edit connections' once in the query editor v2 for the first code block to work, refresh if needed.\n",
    "- The model had 100 rows with churn = False (among the 3,000 records in the dataset): Or maybe 100 is the maximum number of rows that the query editor can display?\n",
    "- All of the probabilities are over 0.50, meaning the model was sure it was likely correct\n",
    "\n",
    "#### These are the ARNs I've saved to use in this homework:\n",
    "\n",
    "Bucket uw-kilpas-mlredshift arn:\n",
    "arn:aws:s3:::uw-kilpas-mlredshift\n",
    "\n",
    "cluster arn: \n",
    "arn:aws:redshift:us-east-1:224609027264:namespace:3df39039-c09a-41dc-b044-189ed8532f8f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Answers\n",
    "### Answers to the following questions:\n",
    "\n",
    "### **What does each of the parameters of the COPY statement we used above do?**\n",
    "```\n",
    "COPY DEMO_ML.customer_activity \n",
    "FROM 's3://redshift-downloads/redshift-ml/customer_activity/' \n",
    "IAM_ROLE '${IAM_ROLE}'\n",
    "delimiter ',' \n",
    "IGNOREHEADER 1  \n",
    "region 'us-east-1'\n",
    ";\n",
    "```\n",
    "- The COPY statement loads data into Redshift, from s3, into the new schema named DEMO_ML.\n",
    "- The IAM_ROLE parameter specifies the Amazon Resource Name (ARN) which is specific for the role that the cluster uses for authentication. Without the correct role (labrole in this case) this query trips an error.\n",
    "- The delimiter parameter specifies which character delimits the data, since Redshift's default is the pipe character (|)\n",
    "- Since ignoreheader is specified, the COPY statement ignores the header as a line of data.\n",
    "- The region specifies where the server supporting the cluster is running out of.\n",
    "\n",
    "you can see more about these specific parameter definitions ([here]https://docs.aws.amazon.com/redshift/latest/dg/r_COPY-parameters.html).\n",
    "\n",
    "### **What is the difference between the `predict_customer_churn` and `predict_customer_churn_prob` functions used in the SQL code? When would you use each one?**\n",
    "\n",
    "- Both functions pull the same information from the data, but the 'predict_customer_churn_prob' function is different from the 'predict_customer_churn' function in that it outputs only of the records that it incorrectly predicted, along with the probability that came with its prediction, vs. all predictions:\n",
    "```\n",
    "SELECT *  FROM infer_data where churn!=predicted vs. SELECT * FROM infer_data\n",
    "```\n",
    "- I would use the 'predict_customer_churn_prob' function for debugging or taking a look at how the model is performing, and I would use the output from `predict_customer_churn` to communicate my results to others.\n",
    "\n",
    "### **Explain the purpose of the two WITH clauses used in the SQL code to review the model's performance. What are these WITH clauses doing? Why are they useful?**\n",
    "\n",
    "- The first WITH clause compares the model's classification (churned/not churned) with the reality of the customer's status. This is useful because it helps check how close the model's output is to reality.\n",
    "\n",
    "- The second WITH clause compares the model's classification and likelihood of being correct with the reality of the customer's status, but this one outputs all instances the model failed to classify the customer correctly. This is also useful because it helps check how well the model is performing, and how \"sure\" it is that it's right.\n",
    "\n",
    "### **When would you want to use ML within Reshift? When would you not?**\n",
    "\n",
    "- ML is good to use in Redshift with large and structured datasets. It is easy to provide the datasets and the service directly preprocesses the data and automates the hyperparameter tuning, which would help beginning and busy ML teams.\n",
    "\n",
    "- However, Redshift may not be the correct approach when dealing with high transaction-based workloads, or complicated entity-relationship schemas (since Redshift does not have tools to show how unique/not redundant the schema is). Furthermore, using ML models in redshift is expensive, and companies or research groups may not have the budget for it.\n",
    "\n",
    "These responses were informed by [this article by Amazon](https://docs.aws.amazon.com/redshift/latest/dg/machine_learning.html) and [this article](https://www.cloudzero.com/blog/aws-redshift/)\n",
    "\n",
    "### **Review the features available in the source data. Write an alternative CREATE MODEL statement with a different set of features. You do not need to execute the statement. Why did you select these features?**\n",
    "The original was:\n",
    "```\n",
    "CREATE TABLE demo_ml.customer_activity (\n",
    "state varchar(2), \n",
    "account_length int, \n",
    "area_code int,\n",
    "phone varchar(8), \n",
    "intl_plan varchar(3), \n",
    "vMail_plan varchar(3),\n",
    "vMail_message int, \n",
    "day_mins float, \n",
    "day_calls int, \n",
    "day_charge float,\n",
    "total_charge float,\n",
    "eve_mins float, \n",
    "eve_calls int, \n",
    "eve_charge float, \n",
    "night_mins float,\n",
    "night_calls int, \n",
    "night_charge float, \n",
    "intl_mins float, \n",
    "intl_calls int,\n",
    "intl_charge float, \n",
    "cust_serv_calls int, \n",
    "churn varchar(6),\n",
    "record_date date)\n",
    ";\n",
    "```\n",
    "and mine would include variables from three separate categories, to analyze customer loss through three different lenses. These would be the company efficacy, with variables such as charge_amount or subscription_length; customer demographics, which includes variables like age_group and status; finally, I would look at the customer's tangible interactions with the company, such as call_failure, complains, or frequency_of_use:\n",
    "\n",
    "CREATE TABLE demo_ml.customer_activity (\n",
    "call_failure int,\n",
    "complains int,\n",
    "subscription_length int,\n",
    "charge_amount int,\n",
    "seconds_of_use int,\n",
    "frequency_of_use int,\n",
    "age_group int,\n",
    "tariff_plan int,\n",
    "status int,\n",
    "customer_value str,\n",
    "churn int)\n",
    ";"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
